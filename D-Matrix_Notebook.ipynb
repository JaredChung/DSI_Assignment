{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSI Assessment 2 - Quantified Self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment will be using the CRISP DM Framework to complete the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Contents Page\n",
    "\n",
    "* Business Understanding\n",
    "* Data Knowledge\n",
    "* Data Processing\n",
    "* Data Exploration\n",
    "* \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is about exporting the information and processing it in a matter which can be later processed and explored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Data Munging tool\n",
    "import os # Operating System functionality\n",
    "import glob # Finds all pathnames e.g(.json)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # Combines both Count Vectorizer and Tfidf Transformer\n",
    "import re # Regular Expression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from nltk.\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users = pd.read_json(\"users.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36100-dsi\n",
      "36100-dsi-photos\n",
      "36103-statistics\n",
      "36106-dam\n",
      "File contains .json\n",
      "crisp-businessknow\n",
      "crisp-dataknow\n",
      "crisp-dataprep\n",
      "crisp-deploy\n",
      "crisp-eval\n",
      "crisp-modelling\n",
      "dam\n",
      "dsi\n",
      "dsi-assignment-2a\n",
      "general\n",
      "File contains .json\n",
      "jira-discussion\n",
      "python_instructions\n",
      "random\n",
      "story-telling\n",
      "File contains .json\n"
     ]
    }
   ],
   "source": [
    "path_to_json = 'C:/users/jchung/desktop/D-Matrix/'\n",
    "json_dir = os.listdir(path_to_json)\n",
    "#del json_dir[0] ### do this step only if u have a mac and need to get rid of .DS Store folder\n",
    "df3 = pd.DataFrame()\n",
    "for file in json_dir:\n",
    "    if \".json\" not in file: \n",
    "        print (file)\n",
    "        all_files = glob.glob(os.path.join(path_to_json + file + '/', \"*.json\"))\n",
    "        df = pd.concat((pd.read_json(f) for f in all_files)) \n",
    "        df['channel'] = file\n",
    "        df['ts'] = pd.to_datetime(df['ts'],unit='s')\n",
    "        df2 = pd.DataFrame(df, columns = ['user','ts','channel','text'])\n",
    "        df3 = df3.append(df2)\n",
    "    else:\n",
    "        print \"File contains .json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below Script is from Martin and need to incorporate this into my script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu May 5 00:04:29 2016\n",
    "@author: Dmatrix\n",
    "\"\"\"\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "import ijson\n",
    "crisp_mapper = {\n",
    "    'crisp-businessknow': 'Business Understanding',\n",
    "    'crisp-dataknow': 'Data Understanding',\n",
    "    'crisp-dataprep': 'Data Preparation',\n",
    "    'crisp-modelling': 'Modelling',\n",
    "    'crisp-eval': 'Evaluation',\n",
    "    'crisp-deploy': 'Deployment',\n",
    "    'story-telling': 'Deployment',\n",
    "    '36100-dsi': 'General',\n",
    "    '36100-dsi-photos': 'General',\n",
    "    '36103-statistics': 'General',\n",
    "    '36106-dam': 'General',\n",
    "    'dsi-assignment-2a': 'General',\n",
    "    'random': 'General',\n",
    "    'general': 'General'\n",
    "}\n",
    "user_mapper = {\n",
    "    'u0weaa087': 'Data Scientist 2',\n",
    "    'u0wdyeg6s': 'Business Analyst',\n",
    "    'u0x443ckz': 'Data Scientist 1',\n",
    "    'u0wfhmem8': 'Data Analytics Manager',\n",
    "    'u0x6cuq3d': 'Project Manager',\n",
    "    'u13aj8evd': 'Bender the Scrum Master',\n",
    "    'howdy': 'Bender the Scrum Master',\n",
    "    'duhita': 'Business Analyst',\n",
    "    'jared': 'Data Scientist 2',\n",
    "    'martin': 'Project Manager',\n",
    "    'hussam': 'Data Analytics Manager',\n",
    "    'chris': 'Data Scientist 1',\n",
    "    'chris.garces': 'Data Scientist 1',\n",
    "    'martinlehmann': 'Project Manager',\n",
    "    'ravi': 'Consultant'\n",
    "}\n",
    "def extract(directory='.\\data'):\n",
    "    \"\"\"Extract timestamp, user, text features from slack extracts\n",
    "    Args:\n",
    "        directory: The root directory folder where the slack extracts are located.\n",
    "    Returns:\n",
    "        a list of lists where each list contains the timestamp, user and text data.\n",
    "        Ignores Bot Messages that are not Howdy\n",
    "        Ignores File Comments\n",
    "        Ignores Channel creation messages\n",
    "        Ignores Channel purpose messages\n",
    "        Ignores file shares\n",
    "    \"\"\"\n",
    "    slack_records = []\n",
    "    row_filter = ['file_comment', 'bot_message', 'channel_purpose', 'channel_join', 'file_share']\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            crisp_activity = subdir.split(\"\\\\\")[2]  # HACK: get channel data\n",
    "            with open(os.path.join(subdir, file)) as json_file:\n",
    "                records = ijson.items(json_file, '')\n",
    "                for record in records:\n",
    "                    for message in record:\n",
    "                        if message.get('subtype') in row_filter and message.get('username') != 'howdy':\n",
    "                            continue\n",
    "                        user = message.get('user')\n",
    "                        # check if user is howdy\n",
    "                        if message.get('subtype') == 'bot_message' and user is None:\n",
    "                            user = message.get('username')\n",
    "                        current_record = [message.get('ts'),\n",
    "                                          user,\n",
    "                                          message.get('text'),\n",
    "                                          crisp_mapper.get(crisp_activity)]\n",
    "                        slack_records.append(current_record)\n",
    "    return slack_records\n",
    "def first_pass_cleaning(slack_records):\n",
    "    \"\"\" Transforms the slack record input addressing:\n",
    "        1) Transform slack timestamp to date\n",
    "        2) Transform email for positive sentiment of sharing\n",
    "        3) Transform links for positive sentiment of sharing\n",
    "        4) Remove unnecessary links from Howdy Bot\n",
    "        5) Mask user information to project role\n",
    "        6) Lower case words\n",
    "        7) Sorts records by time\n",
    "        8) Convert to ascii\n",
    "        spelling, abbreviations\n",
    "    Args:\n",
    "        slack_records: Raw input from slack extract.\n",
    "    Returns:\n",
    "        A list of cleaned data representing each slack message.\n",
    "    \"\"\"\n",
    "    for slack_record in slack_records:\n",
    "        # transform timestamp to date\n",
    "        slack_record[0] = timestamp_to_datetime(slack_record[0])\n",
    "        # transform email\n",
    "        slack_record[2] = mail_to_text(slack_record[2])\n",
    "        # Slack links to be changed to \"Sharing a link!\"\n",
    "        # exclamation for positive sentiment, sharing should be viewed positively\n",
    "        slack_record[2] = links_to_text(slack_record[2])\n",
    "        # Remove Bender's comments that are not english\n",
    "        slack_record[2] = bender_to_english(slack_record[2])\n",
    "        # transform user\n",
    "        slack_record[1] = user_mapper.get(str.lower(slack_record[1]))\n",
    "        # decode data\n",
    "        slack_record[2] = slack_record[2].encode('utf-8').decode('ascii', 'ignore')\n",
    "    # sort records by time\n",
    "    slack_records.sort(key=lambda x: datetime.datetime.strptime(x[0], '%Y-%m-%d %H:%M:%S'))\n",
    "    # convert to bag of words / or sentences\n",
    "    bag_of_words_list = []\n",
    "    #spelling\n",
    "    #abbreviation\n",
    "    for slack_record in slack_records:\n",
    "        # lower case message\n",
    "        slack_record[2] = str.lower(slack_record[2])\n",
    "        # mask user in message\n",
    "        for key, value in user_mapper.items():\n",
    "            slack_record[2] = slack_record[2].replace(key, value)\n",
    "        # Slack calling out a user: Replace \"<@user>:\" with \"user,\" or \"<@user>\" with \"user\"\n",
    "        for key, value in user_mapper.items():\n",
    "            slack_record[2] = slack_record[2].replace(str.format(\"<@{0}>:\", value), str.format(\"{0},\", value))\n",
    "            slack_record[2] = slack_record[2].replace(str.format(\"<@{0}>\", value), str.format(\"{0}\", value))\n",
    "    #TODO\n",
    "    return slack_records\n",
    "def replace_code_with_semantic_intent(message):\n",
    "    # if messasge contains : { [ ] }\n",
    "    nltk.tokenize(message)\n",
    "    return \"\"\n",
    "def bender_to_english(message):\n",
    "    return re.sub(r'<http://(d-matrix.)?howdy.ai/([a-zA-ez]+/)+([a-zA-Z]|[0-9])+[|]',\n",
    "                  '',\n",
    "                  message,\n",
    "                  re.I)\n",
    "def links_to_text(message):\n",
    "    return re.sub(r'((ht)|(f))tp[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
    "                  'Sharing a link!',\n",
    "                  message,\n",
    "                  re.I)\n",
    "def mail_to_text(message):\n",
    "    return re.sub(r'(mailto:)?[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+',\n",
    "                  'Here is my email!',\n",
    "                  message,\n",
    "                  re.I)\n",
    "def timestamp_to_datetime(timestamp):\n",
    "    return datetime.datetime.fromtimestamp(float(timestamp)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "def write_to_csv(records, output_file):\n",
    "    \"\"\"Writes list of slack records to CSV\n",
    "        Args:\n",
    "            records: The list containing all the messages\n",
    "            output_file: the filename csv output\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"')\n",
    "        writer.writerows(records)\n",
    "        #for record in records:\n",
    "            #writer.writerow([x.encode('utf-8') for x in record])\n",
    "         #   writer.writerow(record)\n",
    "def write_output_to_csv(bag_of_words_list, output_file):\n",
    "    \"\"\"Writes list of bag of words to CSV\n",
    "    Args:\n",
    "        bag_of_words_list: The list containing all the bag of words\n",
    "        output_file: the filename csv output\n",
    "    \"\"\"\n",
    "    with open(output_file, 'wb') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"')\n",
    "        for bag_of_words in bag_of_words_list:\n",
    "            writer.writerow(bag_of_words)  # TODO\n",
    "def main(source_directory, output_file):\n",
    "    slack_records = extract(source_directory)\n",
    "    #bag_of_words_list = transform(slack_records)\n",
    "    slack_records = first_pass_cleaning(slack_records)\n",
    "    write_to_csv(slack_records, output_file)\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv[1], sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(s):\n",
    "    \n",
    "    s = re.sub(r'<http://(d-matrix.)?howdy.ai/([a-zA-ez]+/)+([a-zA-Z]|[0-9])+[|]','',s,re.I)\n",
    "    s = re.sub(r'((ht)|(f))tp[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','Sharing a link!',s,\n",
    "                  re.I)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokeniser(s):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.lnse.org/papers/134-I3007.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def lemma_tokens(tokens, lemma):\n",
    "    lemmatized = []\n",
    "    for item in tokens:\n",
    "        lemmatized.append(lemma.lemmatize(item))\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = pd.merge(df3,users,left_on='user',right_on='id',how='inner')\n",
    "data = data[['user','ts','channel','text','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2940 entries, 0 to 2939\n",
      "Data columns (total 5 columns):\n",
      "user       2940 non-null object\n",
      "ts         2940 non-null datetime64[ns]\n",
      "channel    2940 non-null object\n",
      "text       2940 non-null object\n",
      "name       2940 non-null object\n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 137.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>ts</th>\n",
       "      <th>channel</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-03 23:32:26.000002</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>&lt;@U0WEAA087|jared&gt; has joined the channel</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-03 23:32:27.000003</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>&lt;@U0WEAA087|jared&gt; set the channel purpose: Ch...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-04 10:24:28.000009</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>Yeah trying to get it done. I'm hoping to smas...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-11 06:07:57.000119</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>Hey Guys, sorry haven't been that active. I'm ...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-11 06:11:39.000120</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>&lt;http://nicomiceli.com/slackalytics/&gt; I might ...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user                         ts    channel  \\\n",
       "0  U0WEAA087 2016-04-03 23:32:26.000002  36100-dsi   \n",
       "1  U0WEAA087 2016-04-03 23:32:27.000003  36100-dsi   \n",
       "2  U0WEAA087 2016-04-04 10:24:28.000009  36100-dsi   \n",
       "3  U0WEAA087 2016-04-11 06:07:57.000119  36100-dsi   \n",
       "4  U0WEAA087 2016-04-11 06:11:39.000120  36100-dsi   \n",
       "\n",
       "                                                text   name  \n",
       "0          <@U0WEAA087|jared> has joined the channel  jared  \n",
       "1  <@U0WEAA087|jared> set the channel purpose: Ch...  jared  \n",
       "2  Yeah trying to get it done. I'm hoping to smas...  jared  \n",
       "3  Hey Guys, sorry haven't been that active. I'm ...  jared  \n",
       "4  <http://nicomiceli.com/slackalytics/> I might ...  jared  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crisp-dataprep         1159\n",
       "36100-dsi               542\n",
       "general                 301\n",
       "crisp-businessknow      249\n",
       "36106-dam               147\n",
       "python_instructions     138\n",
       "dsi-assignment-2a       135\n",
       "crisp-dataknow          116\n",
       "story-telling            95\n",
       "jira-discussion          91\n",
       "crisp-modelling          66\n",
       "random                   61\n",
       "36100-dsi-photos         44\n",
       "36103-statistics          6\n",
       "crisp-deploy              5\n",
       "crisp-eval                5\n",
       "dam                       2\n",
       "dsi                       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.channel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantified self - Jared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jared = data[data.name == 'jared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>ts</th>\n",
       "      <th>channel</th>\n",
       "      <th>text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-03 23:32:26.000002</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>&lt;@U0WEAA087|jared&gt; has joined the channel</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-03 23:32:27.000003</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>&lt;@U0WEAA087|jared&gt; set the channel purpose: Ch...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-04 10:24:28.000009</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>Yeah trying to get it done. I'm hoping to smas...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-11 06:07:57.000119</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>Hey Guys, sorry haven't been that active. I'm ...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0WEAA087</td>\n",
       "      <td>2016-04-11 06:11:39.000120</td>\n",
       "      <td>36100-dsi</td>\n",
       "      <td>&lt;http://nicomiceli.com/slackalytics/&gt; I might ...</td>\n",
       "      <td>jared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user                         ts    channel  \\\n",
       "0  U0WEAA087 2016-04-03 23:32:26.000002  36100-dsi   \n",
       "1  U0WEAA087 2016-04-03 23:32:27.000003  36100-dsi   \n",
       "2  U0WEAA087 2016-04-04 10:24:28.000009  36100-dsi   \n",
       "3  U0WEAA087 2016-04-11 06:07:57.000119  36100-dsi   \n",
       "4  U0WEAA087 2016-04-11 06:11:39.000120  36100-dsi   \n",
       "\n",
       "                                                text   name  \n",
       "0          <@U0WEAA087|jared> has joined the channel  jared  \n",
       "1  <@U0WEAA087|jared> set the channel purpose: Ch...  jared  \n",
       "2  Yeah trying to get it done. I'm hoping to smas...  jared  \n",
       "3  Hey Guys, sorry haven't been that active. I'm ...  jared  \n",
       "4  <http://nicomiceli.com/slackalytics/> I might ...  jared  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "crisp-dataprep         63\n",
       "python_instructions    29\n",
       "36100-dsi              21\n",
       "36106-dam              17\n",
       "general                13\n",
       "crisp-businessknow     10\n",
       "random                  7\n",
       "story-telling           5\n",
       "dsi-assignment-2a       1\n",
       "36100-dsi-photos        1\n",
       "crisp-dataknow          1\n",
       "crisp-deploy            1\n",
       "crisp-modelling         1\n",
       "crisp-eval              1\n",
       "jira-discussion         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jared.channel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting messages over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ts\n",
       "0     11\n",
       "1     11\n",
       "2      9\n",
       "3      1\n",
       "4      2\n",
       "5      6\n",
       "6     28\n",
       "7      4\n",
       "8     11\n",
       "9     15\n",
       "10    26\n",
       "11    18\n",
       "12     6\n",
       "13     1\n",
       "20     5\n",
       "21     3\n",
       "23    15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jared.groupby(jared.ts.apply(lambda x: x.hour)).text.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bar() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-757f40a1a1b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Aggregated Hours\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hours\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bar() takes at least 3 arguments (2 given)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAECCAYAAADEhB9lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI84A0Iw4A0Az4gwAzfwPfWN26giZGKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcb7d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,4))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.bar(jared.groupby(jared.ts.apply(lambda x: x.hour)).text.size())\n",
    "fig.suptitle(\"Aggregated Hours\",fontsize= 14)\n",
    "ax.set_xlabel(\"Hours\")\n",
    "ax.set_xticks(jared.groupby(jared.ts.apply(lambda x: x.hour)).text.size().index)\n",
    "ax.set_ylabel(\"Quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax.bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
